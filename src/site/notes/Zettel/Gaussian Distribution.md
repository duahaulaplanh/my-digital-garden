---
{"dg-publish":true,"permalink":"/zettel/gaussian-distribution/","noteIcon":"üìù","created":"2024-04-22T12:17:03.261+07:00","updated":"2024-04-23T07:59:24.106+07:00"}
---

**Ph√¢n ph·ªëi chu·∫©n** (Gaussian Distribution ho·∫∑c Normal Distribution), k√≠ hi·ªáu l√† $\mathcal{N}(x \mid \mu, \sigma^2)$, s·∫Ω ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a nh∆∞ sau:
$$
\mathcal{N}(x \mid \mu, \sigma^2) = \frac{1}{(2\pi \sigma^2)^{1/2}} \exp \left\{ - \frac{1}{2\sigma^2} (x - \mu)^2 \right\}
$$
V·ªõi $x$ l√† s·ªë th·ª±c v√† $\mathcal{N}(x \mid \mu, \sigma^2)$ c√≥ nghƒ©a l√† ph√¢n ph·ªëi g·ªìm 2 tham s·ªë l√† $\mu$ v√† $\sigma^2$, trong ƒë√≥ $\mu$ l√† **trung b√¨nh** (mean) c·ªßa ph√¢n ph·ªëi, $\sigma^2$ l√† **ph∆∞∆°ng sai** (variance) c·ªßa ph√¢n ph·ªëi.

Ngo√†i ra, n·∫øu l·∫•y cƒÉn c·ªßa ph∆∞∆°ng sai, ta ƒë∆∞·ª£c $\sigma$ v√† ta g·ªçi gi√° tr·ªã ƒë√≥ l√† **ƒë·ªô l·ªách chu·∫©n** (standard derivation) c·ªßa ph√¢n ph·ªëi. C√≤n n·∫øu l·∫•y ngh·ªãch ƒë·∫£o c·ªßa ph∆∞∆°ng sai v√† ƒë·∫∑t gi√° tr·ªã ƒë√≥ l√† $\beta$, t·ª©c l√† $\beta = 1/(\sigma^2)$, ta g·ªçi $\beta$ l√† **ƒë·ªô ch√≠nh x√°c** (precision) c·ªßa ph·ªëi.

>[!note]+
>Khi ta n√≥i m·ªôt bi·∫øn ng·∫´u nhi√™n li√™n t·ª•c $X$ n√†o ƒë√≥ c√≥ ph√¢n ph·ªëi $f$ v·ªõi c√°c tham s·ªë $\theta_{i}$, ta k√≠ hi·ªáu $X \sim f(\theta_{1}, \theta_{2}, \dots)$. V√≠ d·ª•, $X$ c√≥ ph√¢n ph·ªëi chu·∫©n v·ªõi trung b√¨nh l√† $\mu$ v√† ph∆∞∆°ng sai l√† $\sigma^2$ th√¨ ta vi·∫øt $X \sim \mathcal{N}(\mu, \sigma^2)$. Ngo√†i ra khi vi·∫øt $X$ c√≥ ph√¢n ph·ªëi, ta ng·∫ßm hi·ªÉu ph√¢n ph·ªëi ƒë√≥ l√† m·∫≠t ƒë·ªô x√°c su·∫•t (pdf) c·ªßa $X$.

>[!danger]+  M√¨nh l√†m m√†u l√† ch·ªß y·∫øu
>ƒê·ªÉ ch·ª©ng minh ph√¢n ph·ªëi chu·∫©n $\mathcal{N}(x \mid \mu, \sigma^2)$ l√† m·ªôt h√†m m·∫≠t ƒë·ªô x√°c su·∫•t th√¨ ta c·∫ßn ch·ª©ng minh hai t√≠nh ch·∫•t:
>$$
\begin{aligned}
\mathcal{N}(x \mid \mu, \sigma^2) &\geq 0 \\
\int_{-\infty}^{\infty} \mathcal{N}(x \mid \mu, \sigma^2) dx &= 1
\end{aligned}
>$$
>T√≠nh ch·∫•t ƒë·∫ßu ti√™n th√¨ ta d·ªÖ th·∫•y r·ªìi, ƒë·ªÉ ch·ª©ng minh ƒë∆∞·ª£c t√≠nh ch·∫•t th·ª© 2, ta ph·∫£i t√¨m hi·ªÉu th√™m m·ªôt d·∫°ng n·ªØa c·ªßa ph√¢n ph·ªëi chu·∫©n, ƒë∆∞·ª£c g·ªçi l√† **ph√¢n ph·ªëi chu·∫©n t·∫Øc** (standard normal distribution), k√≠ hi·ªáu $\varphi(z)$. Ph√¢n ph·ªëi chu·∫©n t·∫Øc ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a nh∆∞ sau:
>$$
\varphi(z) = \frac{1}{(2\pi)^{1/2}} \exp \left\{ -\frac{1}{2}z^2 \right\}
>$$
>Ngo√†i ra, ph√¢n ph·ªëi chu·∫©n t·∫Øc c√≥ trung b√¨nh l√† $0$ v√† ph∆∞∆°ng sai l√† $1$. N·∫øu ƒë·∫∑t $z = (x - \mu) / sigma$ th√¨ ta c√≥ th·ªÉ ƒë∆∞a ph√¢n ph·ªëi chu·∫©n t·∫Øc v·ªÅ ph√¢n ph·ªëi chu·∫©n nh∆∞ sau:
>$$
\mathcal{N}(x \mid \mu, \sigma^2) = \frac{1}{\sigma} \varphi\left( \frac{x-\mu}{\sigma} \right)
>$$
>Gi·ªù x√©t t√≠ch ph√¢n c·ªßa ph√¢n ph·ªëi chu·∫©n, ta c√≥:
>$$
\begin{aligned}
&\int_{-\infty}^{\infty} \frac{1}{(2\pi \sigma^2)^{1/2}} \exp \left\{ - \frac{1}{2\sigma^2} (x - \mu)^2 \right\} dx \\
= \frac{1}{(2\pi \sigma^2)^{1/2}} &\int_{-\infty}^{\infty} \exp \left\{ - \frac{1}{2\sigma^2} (x - \mu)^2 \right\} dx \\
\end{aligned}
>$$
>ƒê·∫∑t $z = (x - \mu) / \sigma$ (m·ª•c ƒë√≠ch ƒë∆∞a t√≠ch ph√¢n tr√™n v·ªÅ t√≠ch ph√¢n c·ªßa ph√¢n ph·ªëi chu·∫©n t·∫Øc), ta c√≥ $x = z \sigma + \mu \implies dx = \sigma dz$. ƒê·ªïi bi·∫øn t√≠ch ph√¢n tr√™n t·ª´ $x$ sang $z$ ta ƒë∆∞·ª£c:
>$$
\begin{aligned}
&\frac{1}{(2\pi \sigma^2)^{1/2}} \int_{-\infty}^{\infty} \exp \left\{ - \frac{1}{2} z^2 \right\} \sigma dz \\
= &\frac{1}{(2\pi)^{1/2}} \int_{-\infty}^{\infty} \exp \left\{ - \frac{1}{2} z^2 \right\} dz \\
\end{aligned}
>$$
>L∆∞u √Ω, t√≠ch ph√¢n sau:
>$$
\int_{-\infty}^{\infty} \exp\{-y^2\}dy = \sqrt{ \pi }
>$$
>c√≤n ƒë∆∞·ª£c g·ªçi l√† **t√≠ch ph√¢n Gauss** ([Gaussian integral - Wikipedia](https://en.wikipedia.org/wiki/Gaussian_integral)) m√¨nh s·∫Ω kh√¥ng ch·ª©ng minh m√† d√πng lu√¥n (ch·ª©ng minh kh√¥ng n·ªïi ü•≤). N·∫øu ti·∫øp t·ª•c ƒë·∫∑t $y^2 = z^2 / 2 \implies \sqrt{ 2 } y = z$ th√¨ ta c√≥ $\sqrt{ 2 }dy = dz$, ta ƒë∆∞·ª£c:
>$$
\begin{aligned}
&\frac{1}{(2\pi)^{1/2}} \int_{-\infty}^{\infty} \exp \left\{ - y^2 \right\} \sqrt{ 2 } dy \\
&= \frac{1}{(2\pi)^{1/2}} \sqrt{ 2 } \sqrt{ \pi } \\
&= 1
\end{aligned}
>$$

Ta c√≥ k√¨ v·ªçng c·ªßa m·ªôt bi·∫øn ng·∫´u nhi√™n $X \sim \mathcal{N}(\mu, \sigma^2)$ l√†:
$$
\mathbb{E}[X] = \int_{-\infty}^{\infty} \mathcal{N}(x \mid \mu, \sigma^2)x dx = \mu
$$
V·∫≠y k√¨ v·ªçng c·ªßa $X$ ch√≠nh l√† gi√° tr·ªã trung b√¨nh c·ªßa ph√¢n ph·ªëi. Ngo√†i ra, ta c√≥:
$$
\mathbb{E}[X^2] = \int_{-\infty}^{\infty} \mathcal{N}(x \mid \mu, \sigma^2)x^2 dx = \mu^2 + \sigma^2
$$
ta g·ªçi gi√° tr·ªã $\mathbb{E}[X^2]$ l√† **moment b·∫≠c 2** (second order moment) c·ªßa $X$. T∆∞∆°ng t·ª± moment b·∫≠c $k$ c·ªßa $X$ s·∫Ω l√† $\mathbb{E}[X^k]$. T·ª´ hai ph∆∞∆°ng tr√¨nh tr√™n, ta c√≥ ph∆∞∆°ng sai c·ªßa $X$ l√†:
$$
\text{var}[X] = \mathbb{E}[X^2] - \mathbb{E}[X]^2 = \sigma^2
$$
Gi√° tr·ªã l·ªõn nh·∫•t c·ªßa m·ªôt ph√¢n ph·ªëi c√≤n ƒë∆∞·ª£c g·ªçi l√† **mode** v√† ph√¢n ph·ªëi chu·∫©n c√≥ $mode = \mu$, t·ª©c l√†:
$$
\max \mathcal{N}(x \mid \mu, \sigma^2) = \mu
$$
>[!note]+
>Do t√°c gi·∫£ ƒë∆∞a ch·ª©ng minh n√†y v√†o ph·∫ßn b√†i t·∫≠p n√™n m√¨nh c≈©ng s·∫Ω c·ªë g·∫Øng ch·ª©ng minh trong ph·∫ßn b√†i t·∫≠p lu√¥n. Ph·∫ßn b√†i t·∫≠p n·∫±m ·ªü [[Zettel/Exercises Part I\|Exercises Part I]].

X√©t m·ªôt vector $D$ chi·ªÅu g·ªìm c√°c s·ªë th·ª±c $\mathbf{x} =(x_{1}, \dots, x_{D})^T$. Ta ƒë·ªãnh nghƒ©a ph√¢n ph·ªëi chu·∫©n tr√™n vector $\mathbf{x}$ l√†:
$$
\mathcal{N}(\mathbf{x} \mid \pmb{\mu}, \pmb{\Sigma}) = \frac{1}{(2\pi)^{D/2}} \frac{1}{|\pmb{\Sigma}|^{1/2}} \exp \left\{ -\frac{1}{2} (\mathbf{x} - \pmb{\mu})^T \pmb{\Sigma}^{-1} (\mathbf{x} - \pmb{\mu}) \right\}
$$
trong ƒë√≥ $\pmb{\mu}$ l√† vector trung b√¨nh c·ªßa ph√¢n ph·ªëi c√≥ $D$ chi·ªÅu, $\pmb{\Sigma}$ l√† ma tr·∫≠n hi·ªáp ph∆∞∆°ng sai c√≥ k√≠ch th∆∞·ªõc $D \times D$ v√† $|\pmb{\Sigma}|$ l√† ƒë·ªãnh th·ª©c c·ªßa ma tr·∫≠n hi·ªáp ph∆∞∆°ng sai $\pmb{\Sigma}$. M·ªôt t√™n g·ªçi kh√°c cho ph√¢n ph·ªëi chu·∫©n nhi·ªÅu chi·ªÅu l√† **multivariate normal (ho·∫∑c gaussian) distribution**.

>[!danger]+
>M√¨nh kh√¥ng th·ªÉ g√µ ƒë∆∞·ª£c ch·ªØ $x$ nh∆∞ trong s√°ch üò≠. N√™n m√¨nh d√πng k√≠ hi·ªáu l√† $\mathcal{D}$ v·∫≠y.

Gi·∫£ s·ª≠ ta c√≥ m·ªôt t·∫≠p d·ªØ li·ªáu $\mathcal{D} = (y_1, \dots, y_N)^T$. T·∫≠p d·ªØ li·ªáu bao g·ªìm $N$ quan s√°t, m·ªói quan s√°t (observation) l√† m·ªôt ƒë·∫°i l∆∞·ª£ng v√¥ h∆∞·ªõng (scalar) $y_{i}$.

>[!note]+
>Ta g·ªçi m·ªôt gi√° tr·ªã $x$ l√† scalar n·∫øu n√≥ kh√¥ng ph·∫£i l√† vector (ez huh). ƒê√∫ng h∆°n, scalar (hay ƒë·∫°i l∆∞·ª£ng v√¥ h∆∞·ªõng) ƒë·ªÉ ch·ªâ ph·∫ßn t·ª≠ c·ªßa m·ªôt tr∆∞·ªùng (field) ([Scalar (mathematics) - Wikipedia](https://en.wikipedia.org/wiki/Scalar_(mathematics))). T·∫≠p s·ªë th·ª±c ($\mathbb{R}$) l√† m·ªôt tr∆∞·ªùng, do ƒë√≥ ta c√≥ th·ªÉ n√≥i c√°c s·ªë th·ª±c $x \in \mathbb{R}$ l√† m·ªôt ƒë·∫°i l∆∞·ª£ng v√¥ h∆∞·ªõng. Ngo√†i ra, t·∫≠p s·ªë ph·ª©c $\mathbb{C}$ c≈©ng l√† m·ªôt tr∆∞·ªùng n√™n $x$ c≈©ng c√≥ th·ªÉ l√† s·ªë ph·ª©c n·∫øu ta ch·ªâ n√≥i $x$ l√† ƒë·∫°i l∆∞·ª£ng v√¥ h∆∞·ªõng m√† kh√¥ng n√≥i g√¨ th√™m.

Gi·∫£ s·ª≠ c√°c quan s√°t trong t·∫≠p d·ªØ li·ªáu $\mathcal{D}$ c·ªßa ta ƒë∆∞·ª£c l·∫•y ra m·ªôt c√°ch ƒë·ªôc l·∫≠p (drawn independently) t·ª´ m·ªôt ph√¢n ph·ªëi chu·∫©n c√≥ trung b√¨nh l√† $\mu$ v√† ph∆∞∆°ng sai l√† $\sigma^2$ (ƒë√¢y l√† hai ƒë·∫°i l∆∞·ª£ng m√† ta ch∆∞a bi·∫øt v√† m·ª•c ƒë√≠ch c·ªßa ch√∫ng ta l√† t√¨m ra ƒë∆∞·ª£c hai tham s·ªë n√†y t·ª´ t·∫≠p d·ªØ li·ªáu m√† ta c√≥), nghƒ©a l√† $y_i = \mathcal{N}(x_i \mid \mu, \sigma^2)$.

>[!note]+
>·ªû c√¢u "l·∫•y ra m·ªôt c√°ch ƒë·ªôc l·∫≠p", ta c√≥ th·ªÉ hi·ªÉu nh∆∞ sau:
>- "L·∫•y ra" (drawn): t·ª©c l√† c√°c gi√° tr·ªã n√†y ƒë∆∞·ª£c ch·ªçn m·ªôt c√°ch ng·∫´u nhi√™n tr√™n ph√¢n ph·ªëi.
>- "ƒê·ªôc l·∫≠p" (independently): khi ta l·∫•y m·ªôt gi√° tr·ªã m·ªõi, c√°c gi√° tr·ªã tr∆∞·ªõc ƒë√≥ (k·ªÉ c·∫£ sau ƒë√≥) kh√¥ng l√†m ·∫£nh h∆∞·ªüng ƒë·∫øn quy·∫øt ƒë·ªãnh ta l·∫•y gi√° tr·ªã m·ªõi n√†o.

C√°c ƒëi·ªÉm d·ªØ li·ªáu m√†:
- ƒê∆∞·ª£c l·∫•y ra t·ª´ c√πng m·ªôt ph√¢n ph·ªëi (identically distributed).
- ƒê·ªôc l·∫≠p v·ªõi nhau (independent).
th√¨ ƒë∆∞·ª£c n√≥i l√† **ƒë·ªôc l·∫≠p v√† c√≥ ph√¢n ph·ªëi ƒë·ªìng nh·∫•t** (independent and identically distributed) v√† thu√≤ng vi·∫øt t·∫Øt l√† i.i.d.

>[!note]+
>X√©t t·∫≠p d·ªØ li·ªáu $\mathcal{D}$, n·∫øu ta vi·∫øt $\mathcal{D} \overset{i.i.d}{\sim} \mathcal{N}(\mu, \sigma^2)$ t·ª©c l√† t·∫≠p d·ªØ li·ªáu $\mathcal{D}$ l√† ƒë·ªôc l·∫≠p v√† c√≥ ph√¢n ph·ªëi ƒë·ªìng nh·∫•t, ngo√†i ra $\mathcal{D}$ ƒë∆∞·ª£c l·∫•y ra t·ª´ ph√¢n ph·ªëi chu·∫©n.

X√©t h√†m likelihood $\mathcal{L}(\mu, \sigma^2 \mid \mathcal{D})$, b·ªüi v√¨ $\mathcal{D}$ l√† i.i.d n√™n ta c√≥:
$$
\mathcal{L}(\mu, \sigma^2 \mid \mathcal{D}) = p(\mathcal{D} \mid \mu, \sigma^2) = p(y_{1}, \dots, y_{N} \mid \mu, \sigma^2) = \prod_{n=1}^N p(y_{n} \mid \mu, \sigma^2)
$$
>[!note]+
>Nh∆∞ ta ƒë√£ n√≥i ·ªü ph·∫ßn tr∆∞·ªõc ([[Zettel/Introduction (Prob)\|Introduction (Prob)]]), khi $X$ v√† $Y$ ƒë·ªôc l·∫≠p v·ªõi nhau th√¨:
>$$
p(X, Y) = p(X)p(Y)
>$$

Ta c√≥ m·ªôt t·∫≠p d·ªØ li·ªáu $\mathcal{D}$, ta ƒë√£ gi·∫£ s·ª≠ c√°c ƒëi·ªÉm d·ªØ li·ªáu ƒë∆∞·ª£c l·∫•y ra t·ª´ m·ªôt ph√¢n ph·ªëi chu·∫©n $\mathcal{N}(\mu, \sigma^2)$ v·ªõi $\mu$ v√† $\sigma^2$ ch∆∞a bi·∫øt. N·∫øu d·ª± ƒëo√°n ƒë∆∞·ª£c $\mu$ v√† $\sigma^2$, g·ªçi gi√° tr·ªã ƒë·ª± do√°n l√† $\hat{\mu}$ v√† $\hat{\sigma}^2$, th√¨ ta ƒë√£ t√¨m ƒë∆∞·ª£c c√°ch ƒë·ªÉ d·ª± ƒëo√°n $\hat{y}$ t·ª´ m·ªôt m·∫´u $x$ n√†o ƒë√≥, b·∫±ng $\hat{y} = \mathcal{N}(x \mid \hat{\mu}, \hat{\sigma}^2)$.

M·ªôt trong nh·ªØng c√°ch th∆∞·ªùng d√πng ƒë·ªÉ t√¨m c√°c tham s·ªë cho ph√¢n ph·ªëi b·∫±ng c√°ch s·ª≠ d·ª•ng t·∫≠p d·ªØ li·ªáu quan s√°t ƒë∆∞·ª£c l√† t√¨m c√°c tham s·ªë m√† **l√†m c·ª±c ƒë·∫°i** h√†m likelihood (hay c√≤n g·ªçi l√† **maximum likelihood**). Hay n√≥i c√°ch kh√°c:
$$
\hat{\mu}, \hat{\sigma}^2 = \text{arg}\max_{\mu, \sigma^2} \mathcal{L}(\mu, \sigma^2 \mid \mathcal{D})
$$
>[!note]+
>K√≠ hi·ªáu $\displaystyle \text{arg}\max_{x} f(x)$ c√≥ nghƒ©a l√† gi√° tr·ªã $x$ sao cho $f(x)$ l√† l·ªõn nh·∫•t (c·ª±c ƒë·∫°i).

ƒê·ªÖ d·ªÖ d√†ng h∆°n, thay v√¨ t√¨m c√°c tham s·ªë l√†m c·ª±c ƒë·∫°i h√†m likelihood, ta t√¨m c√°c tham s·ªë l√†m c·ª±c ƒë·∫°i h√†m log (log ·ªü ƒë√¢y s·∫Ω ƒë∆∞·ª£c hi·ªÉu l√† $\ln$) c·ªßa h√†m likelihood, nghƒ©a l√†:
$$
\hat{\mu}, \hat{\sigma}^2 = \text{arg}\max_{\mu, \sigma} \ln \mathcal{L}(\mu, \sigma^2 \mid \mathcal{D})
$$
S·ª≠ d·ª•ng c√°ch th·ª©c c·ª±c ƒë·∫°i h√†m log likehood, ta c√≥ th·ªÉ vi·∫øt h√†m likelihood l·∫°i nh∆∞ sau:
$$
\begin{aligned}
\ln \mathcal{L}(\mu, \sigma^2 \mid \mathcal{D}) &= \ln \prod_{n=1}^N p(y_{n} \mid \mu, \sigma^2) \\
&= \left[-\frac{1}{2\sigma^2} \sum_{n=1}^N (y_{n} - \mu)^2 \right] - \frac{N}{2} \ln 2\pi - \frac{N}{2}\ln \sigma^2
\end{aligned}
$$
>[!note]+
>Ta c√≥:
>$$
\begin{aligned}
\ln \mathcal{L}(\mu, \sigma^2 \mid \mathcal{D}) &= \ln \prod_{i=1}^N p(y_{i} \mid \mu, \sigma^2) \\
&= \sum_{i=1}^N \ln p(y_{i} \mid \mu, \sigma^2) \\
&= \sum_{=1}^N \ln \frac{1}{(2\pi\sigma^2)^{1/2}} \exp \left\{ -\frac{1}{2\sigma^2} (y_{i} - \mu)^2 \right\} \\
&= \sum_{i=1}^N \ln (2\pi\sigma^2)^{-1/2} -\frac{1}{2\sigma^2} (y_{i} - \mu)^2 \\
&= \sum_{i=1}^N - \frac{1}{2}\ln 2\pi -\frac{1}{2}\ln \sigma^2 - \frac{1}{2\sigma^2} (y_{i} - \mu)^2 \\
&= \left[-\frac{1}{2\sigma^2} \sum_{i=1}^N (y_{i} - \mu)^2 \right] - \frac{N}{2} \ln 2\pi - \frac{N}{2}\ln \sigma^2
\end{aligned}
>$$

C·ª±c ƒë·∫°i h√†m log likelihood ph√≠a tr√™n b·∫±ng c√°ch d√πng $\mu$, ta c√≥:
$$
\mu_{ML} = \frac{1}{N} \sum_{n=1}^N y_{n}
$$
trong ƒë√≥ $\mu_{ML}$ ƒë∆∞·ª£c g·ªçi l√† **trung b√¨nh m·∫´u** (sample mean) t·ª©c l√† trung b√¨nh c·ªßa c√°c quan s√°t $\{y_n\}$ m√† ta quan s√°t ƒë∆∞·ª£c. C√≤n n·∫øu ta c·ª±c ƒë·∫°i b·∫±ng c√°ch d√πng $\sigma^2$, ta c√≥:
$$
\sigma^2_{ML} = \frac{1}{N} \sum_{n=1}^N (y_{n} - \mu_{ML})^2
$$
ta g·ªçi $\sigma^2_{ML}$ l√† **ph∆∞∆°ng sai m·∫´u** (sample variance), ngo√†i ra ta th·∫•y $\sigma^2_{ML}$ c≈©ng ph·ª• thu·ªôc v√†o $\mu_{ML}$. V·ªÅ l√Ω thuy·∫øt l√† ta c·∫ßn t√≠nh c·∫£ hai c√πng l√∫c (t√¨m b·ªô tham s·ªë l√†m c·ª±c ƒë·∫°i, m√† b·ªô tham s·ªë g·ªìm $n$ bi·∫øn th√¨ t√¨m c√πng l√∫c $n$ bi·∫øn) th·∫ø nh∆∞ng trong tr∆∞·ªùng h·ª£p n√†y, $\mu_{ML}$ kh√¥ng ph·ª• thu·ªôc v√†o $\sigma^2_{ML}$ do ƒë√≥ ta c√≥ th·ªÉ t√¨m $\mu_{ML}$ tr∆∞·ªõc sau ƒë√≥ t√¨m $\sigma^2_{ML}$.

>[!note]+
>Th√¥ng th∆∞·ªùng gi√° tr·ªã trung b√¨nh $\mu$ ƒë∆∞·ª£c g·ªçi trung b√¨nh t·ªïng th·ªÉ (population mean) t∆∞∆°ng t·ª± v·ªõi $\sigma^2$ l√† ph∆∞∆°ng sai t·ªïng th·ªÉ (variance mean), ƒë√¢y l√† gi√° tr·ªã m√† ta kh√¥ng bi·∫øt, th·∫ø nh∆∞ng b·∫±ng c√°ch d√πng m·ªôt ph·∫ßn c·ªßa t·ªïng th·ªÉ (g·ªçi l√† m·∫´u), ta s·∫Ω c·ªë g·∫Øng ∆∞·ªõc l∆∞·ª£ng ƒë∆∞·ª£c gi√° tr·ªã $\mu$ v·ªõi $\sigma^2$ t·ªët nh·∫•t. Nh∆∞ ƒë√£ ch·ª©ng minh ph√≠a tr√™n, gi√° tr·ªã ∆∞·ªõc l∆∞·ª£ng t·ªët nh·∫•t ch√≠nh l√† $\mu_{ML}$ (trung b√¨nh c·ªßa m·∫´u) v√† $\sigma^2_{ML}$ (ph∆∞∆°ng sai c·ªßa m·∫´u).

>[!note]+
>ƒê·ªÉ t√¨m gi√° tr·ªã c·ª±c ƒë·∫°i c·ªßa m·ªôt h√†m, ta ƒë·∫°o h√†m sau ƒë√≥ l·∫•y b·∫±ng $0$. Ta bi·∫øt r·∫±ng $\ln$ l√† m·ªôt h√†m ƒë·ªìng bi·∫øn tr√™n $\mathbb{R}$ do ƒë√≥ gi√° tr·ªã t·∫°i d·∫°o h√†m b·∫±ng $0$ c≈©ng ch√≠nh l√† c·ª±c ƒë·∫°i. Ta s·∫Ω vi·∫øt g·ªçn $\ln \mathcal{L}(\mu, \sigma^2 \mid \mathcal{D})$ th√†nh $\mathcal{L}$.
>
>X√©t c·ª±c ƒë·∫°i b·∫±ng $\mu$, ta c√≥:
>$$
\frac{\partial\mathcal{L}}{\partial\mu} = -\frac{1}{2\sigma^2} \sum_{n=1}^N -2y_{n} + 2\mu 
>$$
>Khi ƒë√≥, gi√° tr·ªã c·∫ßn t√¨m l√†:
>$$
\begin{aligned}
-\frac{1}{2\sigma^2} \sum_{n=1}^N -2y_{n} + 2\mu &= 0 \\
\implies \sum_{n=1}^N -2y_{n} + 2\mu &= 0 \\
\Leftrightarrow 2\sum_{n=1}^N -y_{n} + 2N\mu &= 0 \\
\Leftrightarrow \mu = \frac{1}{N} \sum_{n=1}^N y_{n}
\end{aligned}
>$$
>
>X√©t c·ª±c ƒë·∫°i b·∫±ng $\sigma^2$, ta c√≥:
>$$
\frac{\partial \mathcal{L}}{\partial \sigma^2} = \frac{1}{2\sigma^4} \sum_{n=1}^N (y_{n} - \mu)^2 - \frac{N}{2} \frac{1}{\sigma^2}
>$$
>Khi ƒë√≥, gi√° tr·ªã c·∫ßn t√¨m l√†:
>$$
\begin{aligned}
\frac{1}{2\sigma^4} \sum_{n=1}^N (y_{n} - \mu)^2 - \frac{N}{2} \frac{1}{\sigma^2} = 0 \\
\implies \frac{1}{\sigma^2} \sum_{n=1}^N (y_{n} - \mu)^2 - N = 0 \\
\Leftrightarrow \sigma^2 = \frac{1}{N} \sum_{n=1}^N (y_{n} - \mu)^2
\end{aligned}
>$$

X√©t gi√° tr·ªã k√¨ v·ªçng c·ªßa trung b√¨nh m·∫´u $\mu_{ML}$, ta c√≥:
$$
\begin{aligned}
\mathbb{E}[\mu_{ML}] &= \mathbb{E}\left[ \frac{1}{N} \sum_{n=1}^N y_{n} \right] \\
&= \frac{1}{N} \sum_{n=1}^N \mathbb{E}[y_{n}] \\
&= \frac{1}{N} \sum_{n=1}^N \mu \\
&= \mu
\end{aligned}
$$
c√≥ th·ªÉ th·∫•y, k√¨ v·ªçng c·ªßa trung b√¨nh m·∫´u $\mu_{ML}$ ch√≠nh l√† trung b√¨nh c·ªßa ph√¢n ph·ªëi $\mu$, ƒë√∫ng nh∆∞ ta d·ª± ƒëo√°n, gi√° tr·ªã $\mu_{ML}$ c√≥ th·ªÉ ƒë∆∞·ª£c d√πng ∆∞·ªõc l∆∞·ª£ng r·∫•t t·ªët $\mu$. Th·∫ø nh∆∞ng, n·∫øu x√©t gi√° tr·ªã k√¨ v·ªçng c·ªßa ph∆∞∆°ng sai m·∫´u $\sigma^2_{ML}$, ta c√≥:
$$
\mathbb{E}[\sigma^2_{ML}] = \frac{(N-1)}{N} \sigma^2
$$
M·∫∑c d√π ∆∞·ªõc l∆∞·ª£ng t·ªët v·ªõi $\mu_{ML}$ th·∫ø nh∆∞ng $\sigma^2_{ML}$ th√¨ kh√¥ng. D√πng $\sigma^2_{ML}$ ƒë·ªÉ ∆∞·ªõc l∆∞·ª£ng cho $\sigma^2$ th√¨ cho ra gi√° tr·ªã th·∫•p h∆°n, ta g·ªçi c√°ch ∆∞·ªõc l∆∞·ª£ng n√†y l√† **ƒë√°nh gi√° th·∫•p** (underestimate) (hay c√≤n g·ªçi l√† bias). ƒê·ªÉ tr√°nh vi·ªác bias nh∆∞ n√†y, ta ch·ªâ c·∫ßn chia cho $N-1$ thay v√¨ $N$ ·ªü ph∆∞∆°ng sai m·∫´u:
$$
\begin{aligned}
\sigma^2_{ML} &= \frac{1}{N-1} \sum_{n=1}^N (y_{n} - \mu_{ML})^2 \\
\implies \mathbb{E}[\sigma^2_{ML}] &= \sigma^2
\end{aligned}
$$
v√† ƒë√¢y l√† l√Ω do m√† ng∆∞·ªùi ta th∆∞·ªùng chia cho $N-1$ thay v√¨ $N$ ·ªü ph∆∞∆°ng sai m·∫´u.

>[!danger]+ Ph·∫ßn ch·ª©ng minh n√†y h∆°i d√†i ü•≤
>Ta c√≥:
>$$
\begin{aligned}
\mathbb{E}[\sigma^2_{ML}] &= \mathbb{E}\left[ \frac{1}{N} \sum_{n=1}^N (y_{n} - \mu_{{ML}})^2 \right] \\
&= \frac{1}{N} \sum_{n=1}^N \mathbb{E}[(y_{n} - \mu_{ML})^2] \\
&= \frac{1}{N} \sum_{n=1}^N \mathbb{E}[y_{n}^2 -2y_{n}\mu_{ML} + \mu_{ML}^2] \\
&= \frac{1}{N} \sum_{n=1}^N \mathbb{E}[y_{n}^2] -2\mathbb{E}[y_{n}\mu_{ML}] + \mathbb{E}[\mu_{ML}^2] \\
\end{aligned}
>$$
>Nh∆∞ ta ƒë√£ bi·∫øt ·ªü ph·∫ßn tr√™n, moment b·∫≠c 2 c·ªßa $y_n$ hay $\mathbb{E}[y_n^2]$ s·∫Ω l√†:
>$$
\mathbb{E}[y_{n}^2] = \sigma^2 + \mu^2
>$$
>C√≤n gi√° tr·ªã $\mathbb{E}[y_n\mu_{ML}]$ s·∫Ω ƒë∆∞·ª£c t√≠nh nh∆∞ sau (nh·ªõ l√† c√°c quan s√°t ƒë·ªôc l·∫≠p v·ªõi nhau, do ƒë√≥ v·ªõi hai quan s√°t $y_i$ v√† $y_j$ b·∫•t k√¨, ta c√≥ $\mathbb{E}[y_iy_j] = \mathbb{E}[y_i]\mathbb{E}[y_j]$):
>$$
\begin{aligned}
\mathbb{E}[y_{n}\mu_{ML}] &= \mathbb{E}\left[ y_{n} \frac{1}{N} \sum_{i=1}^N y_{i} \right] \\
&= \frac{1}{N} \left[ \sum_{j \neq n} \mathbb{E}[y_{n}y_{j}] + \mathbb{E}[y_{n}^2] \right] \\
&= \frac{1}{N} \left[ (N-1)\mu^2 + \mu^2 + \sigma^2 \right] \\
&= \mu^2 + \frac{\sigma^2}{N}
\end{aligned}
>$$
>Ta ch·ªâ c·∫ßn t√≠nh gi√° tr·ªã c√≤n l·∫°i l√† $\mathbb{E}[\mu_{ML}^2]$. Tr∆∞·ªõc ti√™n ta c·∫ßn bi·∫øt c√¥ng th·ª©c sau:
>$$
\left( \sum_{n=1}^N x_{n} \right)^2 = \sum_{n=1}^N a_{n}^2 + 2\sum_{j=1}^N\sum_{i=1}^j a_{i}a_{j}
>$$
>Ch·ª©ng minh n√†y c√¥ng th·ª©c n√†y m√¨nh thua (c√°c b·∫°n c√≥ th·ªÉ xem th√™m ·ªü [algebra precalculus - What is the square of summation? - Mathematics Stack Exchange](https://math.stackexchange.com/questions/329344/what-is-the-square-of-summation)). Sau khi c√≥ c√¥ng th·ª©c r·ªìi th√¨ t√≠nh th√¥i n√†o:
>$$
\begin{aligned}
\mathbb{E}[\mu_{ML}^2] &= \mathbb{E}\left[ \frac{1}{N^2} \left( \sum_{n=1}^N y_{n} \right)^2 \right] \\
&= \frac{1}{N^2} \mathbb{E}\left[ \sum_{n=1}^N y_{n}^2 + \sum_{j=1}^N\sum_{i=1}^{j-1} y_{i}y_{j} \right] \\
&= \frac{1}{N^2} \left[ \sum_{n=1}^N \mathbb{E}[y_{n}^2] + \sum_{j=1}^N\sum_{i=1}^{j-1} \mathbb{E}[y_{i}y_{j}] \right] \\
&= \frac{1}{N^2} \left( N(\mu^2 + \sigma^2) + 2\sum_{j=1}^N\sum_{i=1}^{j-1} \mu^2 \right)
\end{aligned}
>$$
>·ªû ƒëo·∫°n cu·ªëi, ta th·∫•y nh∆∞ sau:
>$$
\begin{aligned}
\sum_{j=1}^N\sum_{i=1}^{j-1} \mu^2 &= \mu^2 + 2\mu^2 + \dots + (N-1)\mu^2 \\
&= \frac{N(N-1)}{2} \mu^2 \\
\end{aligned}
>$$
>Thay ng∆∞·ª£c v√†o ph∆∞∆°ng tr√¨nh c·ªßa $\mathbb{E}[\mu_{ML}^2]$ ta ƒë∆∞·ª£c:
>$$
\begin{aligned}
\mathbb{E}[\mu_{ML}^2] &= \frac{1}{N^2} \left( N(\mu^2 + \sigma^2) + N(N-1)\mu^2 \right) \\
&= \mu^2 + \frac{\sigma^2}{N} = \mathbb{E}[y_{n}\mu_{ML}]
\end{aligned}
>$$
>Sau khi ƒë√£ c√≥ c·∫£ 3, ta ch·ª©ng minh ƒë∆∞·ª£c, m√¨nh ƒëi ng·ªß ƒë√¢y, d√†i v√£i üíÄ.
>$$
\begin{aligned}
\mathbb{E}[\sigma^2_{ML}] &= \frac{1}{N} \sum_{n=1}^N \mathbb{E}[y_{n}^2] -\mathbb{E}[y_{n}\mu_{ML}] \\
&= \mu^2 + \sigma^2 - \mu^2 - \frac{1}{N}\sigma^2 \\
&= \frac{(N-1)}{N} \sigma^2
\end{aligned}
>$$
>
>My honest reaction:
><center><img width=300 height=300 src="https://preview.redd.it/man-im-dead-v0-ymr5u3c0bjsa1.jpg?auto=webp&s=364c87d710ec0cda25a8e23fcbf1dbd692d0a597"> </center>

Th·∫ø nh∆∞ng khi $N$ tr·ªü l√™n l·ªõn d·∫ßn, vi·ªác bias c·ªßa nghi·ªám c·ªßa maximum likelihood ($\sigma^2_{ML}$) kh√¥ng c√≤n qu√° quan tr·ªçng n·ªØa (v√≠ d·ª• b·∫°n c√≥ $N = 100001$ th√¨ $N - 1 = 100000$ s·∫Ω cho ra k·∫øt qu·∫£ kh√¥ng qu√° ch√™nh l·ªách). Khi m√† $N \to \infty$ th√¨ ph∆∞∆°ng sai m·∫´u $\sigma^2_{ML}$ s·∫Ω ti·∫øn d·∫ßn v·ªÅ ph∆∞∆°ng sai th·ª±c s·ª± $\sigma$ c·ªßa ph√¢n ph·ªëi. Trong th·ª±c t·∫ø, n·∫øu $N$ kh√¥ng nh·ªè th√¨ bias kh√¥ng ph·∫£i l√† m·ªôt v·∫•n ƒë·ªÅ quan tr·ªçng l·∫Øm.

>[!note]+
>Vi·ªác ph∆∞∆°ng sai m·∫´u $\sigma^2_{ML}$ ti·∫øn d·∫ßn v·ªÅ ph∆∞∆°ng sai th·ª±c s·ª± $\sigma$ c·ªßa ph√¢n ph·ªëi khi m√† $N \to \infty$ ƒë∆∞·ª£c ch·ª©ng minh c·ª• th·ªÉ ·ªü **lu·∫≠t s·ªë l·ªõn** (Law of Large Number).
>[Law of large numbers - Wikipedia](https://en.wikipedia.org/wiki/Law_of_large_numbers)
>[probability theory - Sample variance converge almost surely - Mathematics Stack Exchange](https://math.stackexchange.com/questions/243348/sample-variance-converge-almost-surely)

Tuy nhi√™n v·ªõi c√°c m√¥ h√¨nh ML ph·ª©c t·∫°p c√≥ nhi·ªÅu tham s·ªë th√¨ v·∫•n ƒë·ªÅ bias n√†y l·∫°i tr·ªü n√™n nghi√™m tr·ªçng. ·ªû c√°c ph·∫ßn sau, t√°c gi·∫£ s·∫Ω cho th·∫•y v·∫•n ƒë·ªÅ bias c·ªßa maximum likelihood l√† m·ªôt trong nh·ªØng nguy√™n nh√¢n g√¢y ra over-fitting.

---

Ph·∫ßn tr∆∞·ªõc: [[Zettel/Bayesian Probabilities\|Bayesian Probabilities]]
Ph·∫ßn sau: [[Zettel/Curve Fitting Revisited\|Curve Fitting Revisited]]

---
# References

- [Bishop] Pattern Recognition and Machine Learning - Bishop (chapter 1.2)
- [Proof: Integral of PDF of Normal Distribution is Equal to 1 (in English) (youtube.com)](https://www.youtube.com/watch?v=8Ey7v8IoZjA)
- [probability - Expectation of sample variance - Mathematics Stack Exchange](https://math.stackexchange.com/questions/4017763/expectation-of-sample-variance)