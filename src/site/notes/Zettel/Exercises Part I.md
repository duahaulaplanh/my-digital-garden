---
{"dg-publish":true,"permalink":"/zettel/exercises-part-i/","noteIcon":"üìù","created":"2024-04-23T09:04:07.504+07:00","updated":"2024-04-24T12:37:51.240+07:00"}
---

>[!example]+ Gi·∫£i b√†i 1.1
>
>![Pasted image 20240423100559.png](/img/user/Attachment/Pasted%20image%2020240423100559.png)

Ph∆∞∆°ng tr√¨nh (1.1) nh∆∞ sau:
$$
y(x, \mathbf{w}) = \sum_{j=0}^M x^j w_{j}
$$
Ph∆∞∆°ng tr√¨nh (1.2) nh∆∞ sau:
$$
E(\mathbf{w}) = \frac{1}{2} \sum_{n=1}^N \left\{ y(x_{n}, \mathbf{w}) - t_{n} \right\}^2
$$
v·ªõi $(x_1, \dots, x_{n})$ l√† c√°c d·ªØ li·ªáu, $(t_{1}, \dots, t_{n})$ l√† c√°c nh√£n (hay l√† target) v√† $\mathbf{w}$ l√† b·ªô tham s·ªë. ƒê·ªÉ c·ª±c ti·ªÉu ƒë∆∞·ª£c h√†m l·ªói $E(\mathbf{w})$, ta ch·ªâ c·∫ßn t√¨m gi√° tr·ªã $\hat{\mathbf{w}} = (\hat{w}_{1}, \dots, \hat{w}_{M})^T$, sao cho:
$$
\nabla E(\hat{\mathbf{w}}) = \mathbf{0}
$$
v·ªõi $\mathbf{0}$ l√† vector $0$. Do $\nabla E(\mathbf{w})$ l√† m·ªôt vector n√™n ƒë·ªÉ vector b·∫±ng $0$ th√¨ t·ª´ng ph·∫ßn t·ª≠ b·∫±ng $0$, v·∫≠y ta c·∫ßn t√¨m $\hat{w}_{i}$ sao cho:
$$
\frac{\partial{E(\hat{\mathbf{w}})}}{\partial w_{i}} = 0
$$
Gi·ªù b·∫Øt ƒë·∫ßu bi·∫øn ƒë·ªïi ƒë·ªÉ t√¨m ƒë∆∞·ª£c $\hat{w}_i$ th√¥i n√†o. Ta c√≥:
$$
\begin{aligned}
\frac{\partial{E(\hat{\mathbf{w}})}}{\partial w_{i}} &= \frac{1}{2} \sum_{n=1}^N \frac{\partial \{y(x_{n}, \mathbf{w}) - t_{n}\}^2}{\partial w_{i}} \\
&= \frac{1}{2} \sum_{n=1}^N \left[ \frac{\partial y(x_{n}, \mathbf{w})^2}{\partial w_{i}} - 2t_{n} \frac{\partial y(x_{n}, \mathbf{w})}{\partial w_{i}} + \frac{\partial t_{n}^2}{\partial w_{i}} \right] \\
&= \frac{1}{2} \sum_{n=1}^N \left[ 2y(x_{n}, \mathbf{w})\frac{\partial y(x_{n}, \mathbf{w})}{\partial w_{i}} - 2t_{n}x_{n}^i +0 \right] \\
&= \frac{1}{2} \sum_{n=1}^N [2y(x_{n}, \mathbf{w})x_{n}^i -2t_{n}x_{n}^i] \\
&= \sum_{n=1}^N \left[ \sum_{j=0}^M x_{n}^{i+j} w_{j} \right] - \sum_{n=1}^Nt_{n}x_{n}^i
\end{aligned}
$$
·ªû ph∆∞∆°ng tr√¨nh tr√™n, t√°ch ph·∫ßn tr∆∞·ªõc d·∫•u tr·ª´, ta ƒë∆∞·ª£c:
$$
\begin{aligned}
\sum_{n=1}^N \left[ \sum_{j=0}^M x_{n}^{i+j} w_{j} \right] &= \sum_{n=1}^N (x_{n}^{i}w_{0} + \dots x_{n}^{i+M}w_{M}) \\
&= \sum_{n=1}^N x_{n}^iw_{0} + \dots + \sum_{n=1}^N x_{n}^{i+M}w_{M} \\
&= \sum_{j=0}^M \left( \sum_{n=1}^N x_{n}^{i+j} \right) w_{j}
\end{aligned}
$$
Thay v√†o l·∫°i ph∆∞∆°ng tr√¨nh ch·ªó ta c√≥:
$$
\begin{aligned}
\frac{\partial{E(\hat{\mathbf{w}})}}{\partial w_{i}} &= \sum_{n=1}^N \left[ \sum_{j=0}^M x_{n}^{i+j} w_{j} \right] - \sum_{n=1}^Nt_{n}x_{n}^i \\
&= \sum_{j=0}^M \left( \sum_{n=1}^N x_{n}^{i+j} \right) w_{j} - \sum_{n=1}^N t_{n}x_{n}^i
\end{aligned}
$$
ƒê·∫∑t $\sum_{n=1}^N x_{n}^{i+j} = A_{ij}$ v√† $\sum_{n=1}^Nt_{n}x_{n}^i = T_{i}$. Khi ƒë√≥:
$$
\begin{aligned}
\frac{\partial E(\mathbf{w})}{\partial w_{i}} &= 0 \\
\Leftrightarrow \sum_{j=0}^M A_{ij}w_{j} &= T_{i}
\end{aligned}
$$
V·∫≠y gi√° tr·ªã $\hat{w}_i$ c·∫ßn t√¨m ch√≠nh l√† nghi·ªám c·ªßa ph∆∞∆°ng tr√¨nh tr√™n.

>[!example]+ Gi·∫£i b√†i 1.2
>
>![Pasted image 20240423100741.png](/img/user/Attachment/Pasted%20image%2020240423100741.png)

Ph∆∞∆°ng tr√¨nh (1.122) l√† ph∆∞∆°ng tr√¨nh nghi·ªám $\hat{w}_i$ ·ªü b√†i 1.1. C√≤n ph∆∞∆°ng tr√¨nh (1.4) nh∆∞ sau:
$$
\tilde{E}(\mathbf{w}) = \frac{1}{2} \sum_{n=1}^N \{y(x_{n}, \mathbf{w}) - t_{n}\}^2 + \frac{\lambda}{2}||\mathbf{w||^2}
$$
trong ƒë√≥ $||\mathbf{w}||$ ƒë∆∞·ª£c g·ªçi l√† **chu·∫©n** c·ªßa vector $\mathbf{w}$ v√† c√≥ c√¥ng th·ª©c l√†:
$$
||\mathbf{w}|| = \sqrt{ w_{0}^2 + \dots + w_{M}^2 }
$$
Ta c√≥:
$$
\begin{aligned}
\frac{\partial{E(\hat{\mathbf{w}})}}{\partial w_{i}} &= \frac{1}{2} \sum_{n=1}^N \frac{\partial \left( \{y(x_{n}, \mathbf{w}) - t_{n}\}^2 +\frac{\lambda}{2}||\mathbf{w}||^2 \right)}{\partial w_{i}} \\
&= \frac{1}{2} \sum_{n=1}^N \left[ \frac{\partial y(x_{n}, \mathbf{w})^2}{\partial w_{i}} - 2t_{n} \frac{\partial y(x_{n}, \mathbf{w})}{\partial w_{i}} + \frac{\partial t_{n}^2}{\partial w_{i}} + \frac{\lambda}{2} \frac{\partial||\mathbf{w}||^2}{\partial w_{i}} \right] \\
&= \sum_{j=0}^M A_{ij}w_{j} -T_{i} + \sum_{n=1}^N \lambda w_{i} \\
&= \sum_{j=0}^M A_{ij}w_{j} -T_{i} + N\lambda w_{i} \\
\end{aligned}
$$
V·∫≠y gi√° tr·ªã $\hat{w}_i$ ch√≠nh l√† nghi·ªám c·ªßa ph∆∞∆°ng tr√¨nh:
$$
\sum_{j=0}^M A_{ij}w_{j} + N\lambda w_{i} = T_{i}
$$

>[!example]+ Gi·∫£i b√†i 1.3
>
>![Pasted image 20240423103443.png](/img/user/Attachment/Pasted%20image%2020240423103443.png)

B√†i n√†y gi·∫£i kh√° t∆∞∆°ng t·ª± b√†i trong ph·∫ßn [[Zettel/Introduction (Prob)\|Introduction (Prob)]]. M√¨nh ƒë·∫∑t bi·∫øn ng·∫´u nhi√™n $B$ ƒë·∫°i di·ªán cho c√°c h·ªôp m√†u, bi·∫øn ng·∫´u nhi√™n $F$ ƒë·∫°i di·ªán cho tr√°i c√¢y, $F= a$ l√† tr√°i t√°o (apple), $F = o$ l√† tr√°i cam (orange) v√† $F = l$ l√† tr√°i chanh (lime). Ta c√≥:
$$
\begin{aligned}
p(B = r) &= 0.2 \\
p(B = b) &= 0.2 \\
p(B = g) &= 0.6
\end{aligned}
$$
Ti·∫øp theo, ta c√≥ x√°c su·∫•t ch·ªçn ƒë∆∞·ª£c tr√°i t√°o khi ƒë√£ ch·ªçn ƒë∆∞·ª£c m·ªôt h·ªôp m√†u l·∫ßn l∆∞·ª£t l√†:
$$
\begin{aligned}
p(F = a \mid B = r) &= \frac{3}{10} = 0.3 \\
p(F = a \mid B = b) &= \frac{1}{2} = 0.5 \\
p(F = a \mid B = g) &= \frac{3}{10} = 0.3
\end{aligned}
$$
D√πng sum rule, ta l·∫°i c√≥:
$$
\begin{aligned}
p(F = a) &= \sum_{B} p(F=a, B) \\
&= \sum_{B} p(F=a \mid B)p(B) \\
&= p(F=a \mid B = r)p(B = r) + p(F=a \mid B=b)p(B=b) \\
&+ p(F=a \mid B=g)p(B = g) \\
&= 0.3 \times 0.2 + 0.5 \times 0.2 + 0.3 \times 0.6 \\
&= 0.34
\end{aligned}
$$
V·∫≠y x√°c su·∫•t ƒë·ªÉ ch·ªçn ƒë∆∞·ª£c m·ªôt qu·∫£ t√°o l√† $0.34$. ƒê·ªÉ t√¨m x√°c su·∫•t h·ªôp ta ch·ªçn l√† h·ªôp xanh l√° $g$ khi ƒë√£ ch·ªçn ƒë∆∞·ª£c qu·∫£ t√°o, ta t√¨m x√°c su·∫•t $p(B = g \mid F = a)$ b·∫±ng c√°ch d√πng ƒë·ªãnh l√Ω Bayes:
$$
p(B = g \mid F= a) = \frac{p(F=a \mid B=g)p(B =g)}{p(F=a)} = \frac{0.3 \times 0.6}{0.34} \approx 0.52
$$

>[!example]+ Gi·∫£i b√†i 1.4
>
>![Pasted image 20240424110908.png](/img/user/Attachment/Pasted%20image%2020240424110908.png)

Gi·∫£ s·ª≠ ta c√≥ h√†m kh·∫£ vi $f(x)$ v·ªõi $x$ l√† s·ªë th·ª±c (kh√¥ng ph·∫£i bi·∫øn ng·∫´u nhi√™n), ƒë·ªÉ t√¨m gi√° tr·ªã l·ªõn nh·∫•t c·ªßa $f(x)$, ta ƒë·∫°o h√†m $f'(x)$ sau ƒë√≥ cho $f'(x) = 0$ ƒë·ªÉ t√¨m ƒë∆∞·ª£c gi√° tr·ªã $x$ tho·∫£ m√£n, g·ªçi l√† $\hat{x}$ ƒëi.

Ti·∫øp theo, ta c√≥ m·ªôt bi·∫øn m·ªõi l√† $y$ v·ªõi $x = g(y)$. ƒê·ªïi bi·∫øn h√†m $f(x)$ sang $f(g(y))$ (l√† m·ªôt h√†m c·ªßa $y$), ta ƒë·∫∑t $\tilde{f}(y) = f(g(y))$ (ƒë·ªÉ bi·∫øt ƒë√¢y l√† m·ªôt h√†m c·ªßa $y$). ƒê·ªÉ t√¨m gi√° tr·ªã l·ªõn nh·∫•t c·ªßa $\tilde{f}(y)$, ta ƒë·∫°o h√†m v√† sau ƒë√≥ cho b·∫±ng $0$. ƒê·∫ßu ti√™n ƒë·∫°o h√†m:
$$
\begin{aligned}
\frac{d\tilde{f}(y)}{dy} &= \frac{df(g(y))}{g(y)} \frac{dg(y)}{y} \\
\implies  \tilde{f}'(y) &= f'(g(y))g'(y)
\end{aligned}
$$
Sau ƒë√≥ cho b·∫±ng $0$ (g·ªçi gi√° tr·ªã l√†m ƒë·∫°o h√†m b·∫±ng $0$ l√† $\hat{y}$):
$$
\tilde{f}'(\hat{y}) = 0 \implies f'(g(\hat{y})) = 0 \hspace{3pt} \text{ho·∫∑c} \hspace{3pt} g'(\hat{y}) = 0 \hspace{3pt} \text{ho·∫∑c c·∫£ 2 $=0$}
$$
X√©t tr∆∞·ªùng h·ª£p $f'(g(\hat{y})) = 0$, ta th·∫•y r·∫±ng $f'(\hat{x}) = 0$, do ƒë√≥ $f'(g(\hat{y})) = f'(\hat{x}) \implies g(\hat{y}) = \hat{x}$. V·∫≠y c√≥ nghƒ©a l√† ta c√≥ th·ªÉ t√¨m gi√° tr·ªã l·ªõn nh·∫•t c·ªßa $f(x)$ th√¥ng qua $y$ v·ªõi $x = g(y)$. T∆∞∆°ng t·ª± v·ªõi tr∆∞·ªùng h·ª£p $f'(g(\hat{y})) = 0$ v√† $g'(\hat{y}) = 0$.

Tuy nhi√™n ta c·∫ßn ƒë·ªÉ √Ω tr∆∞·ªùng h·ª£p ch·ªâ $g'(\hat{y}) = 0$. Trong solution t√°c gi·∫£ gi·∫£ s·ª≠ lu√¥n $g'(\hat{y}) = 0$ b·ªüi v√¨ ta ch·ªâ quan t√¢m ƒë·∫øn tr∆∞·ªùng h·ª£p $f'(g(\hat{y})) = 0$ th√¥i, vi·ªác $g'(\hat{y}) = 0$ m√† $f'(g(\hat{y})) \neq 0$ c√≥ th·ªÉ ƒë∆∞·ª£c gi·∫£i quy·∫øt b·∫±ng c√°ch ch·ªçn m·ªôt bi·∫øn kh√°c, g·ªçi l√† $t$ ƒëi, l√∫c n√†y $x = \tilde{g}(t)$ v√† ta ƒë∆∞·ª£c $f'(\tilde{g}(\hat{t})) = 0$ v√† ta kh√¥ng c·∫ßn quan t√¢m $\tilde{g}'(\hat{t})$ b·∫±ng $0$ hay kh√°c $0$ n·ªØa. Do m·ª•c ƒë√≠ch l√† t√¨m gi√° tr·ªã l·ªõn nh·∫•t c·ªßa $f(x)$ th√¥ng qua m·ªôt bi·∫øn m·ªõi n√†o ƒë√≥, do ƒë√≥ ta c√≥ th·ªÉ ch·ªçn l·∫°i bi·∫øn m·ªõi sao cho tho·∫£ m√£n c√°c gi·∫£ s·ª≠ c·ªßa ta l√† ƒë∆∞·ª£c.

V·∫≠y ·ªü ƒë√¢y, t√°c gi·∫£ mu·ªën n√≥i l√†, v·ªõi $x$ v√† $y$ (li√™n quan v·ªõi nhau th√¥ng qua $x = g(y)$) kh√¥ng l√† bi·∫øn ng·∫´u nhi√™n th√¨ ta c√≥ th·ªÉ t√¨m gi√° tr·ªã l·ªõn nh·∫•t c·ªßa $f(x)$ th√¥ng qua $y$. Nh∆∞ng ƒë·ªëi v·ªõi hai bi·∫øn ng·∫´u nhi√™n $X$ v√† $Y$ th√¨ vi·ªác n√†y kh√¥ng x·∫£y ra (kh√¥ng th·ªÉ t√¨m gi√° tr·ªã l·ªõn $f(X)$ th√¥ng $Y$) do b·ªã ·∫£nh h∆∞·ªüng b·ªüi jacobian factor.

Gi·ªù x√©t $X$ v√† $Y$ l√† hai bi·∫øn ng·∫´u nhi√™n v·ªõi $X = g(Y$) (l∆∞u √Ω $g$ l√† h√†m kh·∫£ ngh·ªãch). ƒê·∫∑t $p_x$ v√† $p_y$ l·∫ßn l∆∞·ª£t l√† h√†m m·∫≠t ƒë·ªô x√°c su·∫•t c·ªßa $X$ v√† $Y$. ƒê·ªÉ t√¨m ƒë∆∞·ª£c m·∫≠t ƒë·ªô x√°c su·∫•t c·ªßa $Y$, ta d√πng c√¥ng th·ª©c 1.17 nh∆∞ sau:
$$
p_{y}(y) = p_{x}(g(y)) \hspace{2pt} |g'(y)|
$$
Gi·∫£ s·ª≠ gi√° tr·ªã $\hat{x}$ l√† gi√° tr·ªã ƒë·ªÉ l√†m cho $p_x$ l·ªõn nh·∫•t, t·ª©c l√† $p_{x}'(\hat{x}) = 0$. ƒê·ªÉ t√¨m gi√° tr·ªã l·ªõn nh·∫•t c·ªßa $p_y(y)$ ta ƒë·∫°o h√†m v√† sau ƒë√≥ cho gi√° tr·ªã ƒë·∫°o h√†m b·∫±ng $0$. Gi·∫£ s·ª≠ $g'(y) \neq 0$ (khi ƒë√≥ ta m·ªõi c√≥ th·ªÉ ƒë·∫°o h√†m $|g'(y)|$) v√† ƒë·∫∑t $|g'(y)| = sg'(y)$ v·ªõi $s \in \{-1, 1\}$.

ƒê·∫ßu ti√™n ta l·∫•y ƒë·∫°o h√†m:
$$
\begin{aligned}
p_{y}'(y) = \frac{dp_{y}(y)}{dy} &= \frac{dp_{x}(g(y))}{dy} sg'(y) + p_{x}(g(y)) \frac{dsg'(y)}{dy} \\
&= sp_{x}'(g(y))g'(y)\hspace{1pt}|g'(y)| + p_{x}(g(y))\hspace{1pt}sg''(y) \\
&= sp_{x}'(g(y))[g'(y)]^2 + sp_{x}(g(y))\hspace{1pt}g''(y) \\
\end{aligned}
$$
Gi·∫£ s·ª≠ gi√° tr·ªã $\hat{y}$ l√† gi√° tr·ªã ƒë·ªÉ l√†m cho $p_y$ l·ªõn nh·∫•t v√† **gi·∫£ s·ª≠** $\hat{x} = g(\hat{y})$, t·ª©c l√† $p_x(\hat{x}) = p_x(g(\hat{y})) = 0$ (t∆∞∆°ng t·ª± nh∆∞ $x$ v√† $y$ kh√¥ng l√† bi·∫øn ng·∫´u nhi√™n). Khi ƒë√≥:
$$
\begin{aligned}
p_{y}'(\hat{y}) &= sp_{x}'(g(\hat{y}))[g'(\hat{y})]^2 + sp_{x}(g(\hat{y}))\hspace{1pt}g''(\hat{y}) \\ 
&= sp_{x}(g(\hat{y}))g''(\hat{y}) \neq 0
\end{aligned}
$$
V·∫≠y r√µ r√†ng n·∫øu $\hat{y}$ l√† gi√° tr·ªã l√†m cho $p_y$ l·ªõn nh·∫•t v√† $\hat{x} =g(\hat{y})$ th√¨ ƒëi·ªÅu n√†y l·∫°i sai, do ƒë√≥ $\hat{x} \neq g(\hat{y})$. T·ª©c l√† n·∫øu $X$ v√† $Y$ l√† bi·∫øn ng·∫´u nhi√™n th√¨ kh√¥ng c√≥ quan h·ªá n√†o gi·ªØa $\hat{x}$ v√† $g(\hat{y})$, do ƒë√≥ ta kh√¥ng th·ªÉ t√¨m gi√° tr·ªã $X$ l√†m cho $p_x$ l·ªõn nh·∫•t b·∫±ng c√°ch t√¨m gi√° tr·ªã $Y$ l√†m cho $p_y$ l·ªõn nh·∫•t.

Tuy nhi√™n, n·∫øu ta ch·ªçn $g(Y) = X$ sao cho $g$ l√† m·ªôt h√†m tuy·∫øn t√≠nh th√¨ m·ªçi chuy·ªán s·∫Ω kh√°c. Gi·∫£ s·ª≠ $X = g(Y) = \alpha Y + \beta$. Khi ƒë√≥:
$$
p'_{y}(\hat{y}) = sp_{x}(g(\hat{y}))g''(\hat{y}) = 0
$$
Do n·∫øu $g(y) = \alpha y + \beta$ th√¨ $g''(y) = 0$ v·ªõi m·ªçi $y$.

V·∫≠y $p_y'(\hat{y}) = 0 \implies p_x'(g(\hat{y})) = 0 \implies p_x'(\hat{x}) = p_{x}(g(\hat{y})) = 0 \implies  \hat{x} = g(\hat{y})$. Ta c√≥ th·ªÉ th·∫•y b·∫±ng vi·ªác ch·ªçn $g$ l√† m·ªôt h√†m tuy·∫øn t√≠nh th√¨ $\hat{x} = g(\hat{y})$, do ƒë√≥ vi·ªác ch·ªçn h√†m $g$ ƒë·ªÉ bi·∫øn ƒë·ªïi t·ª´ $X$ sang $Y$ l√† r·∫•t quan tr·ªçng.

>[!example]+ Gi·∫£i b√†i 1.5
>
>![Pasted image 20240424123238.png](/img/user/Attachment/Pasted%20image%2020240424123238.png)

ƒê√£ ƒë∆∞·ª£c gi·∫£i trong [[Zettel/Expectations and covariances\|Expectations and covariances]].

>[!example]+ Gi·∫£i b√†i 1.6
>
>![Pasted image 20240424123252.png](/img/user/Attachment/Pasted%20image%2020240424123252.png)

ƒê√£ ƒë∆∞·ª£c gi·∫£i trong [[Zettel/Expectations and covariances\|Expectations and covariances]].

>[!example]+ Gi·∫£i b√†i 1.7
>
>![Pasted image 20240424123337.png](/img/user/Attachment/Pasted%20image%2020240424123337.png)



---

Ph·∫ßn tr∆∞·ªõc: 
Ph·∫ßn sau: 

---
# References

- [Bishop] Pattern Recoginition and Machine Learning (exercises of I.Introduction).
- [prml-web-sol.dvi (microsoft.com)](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/05/prml-web-sol-2009-09-08.pdf)
- [real analysis - Exercise 1.4 from PRML: Process of Using Transformations to Find Modes of PDFs - Mathematics Stack Exchange](https://math.stackexchange.com/questions/3494289/exercise-1-4-from-prml-process-of-using-transformations-to-find-modes-of-pdfs)
- [real analysis - Linear/non-linear change of variables: $\tilde{f} \ ' (\tilde{y}) = f'(g(\tilde{y})) g'(\tilde{y}) = 0$ and assuming $g'(\tilde{y}) \not= 0$ - Mathematics Stack Exchange](https://math.stackexchange.com/questions/3510938/linear-non-linear-change-of-variables-tildef-tildey-fg-tilde)