---
{"dg-publish":true,"permalink":"/thesis/report-2-25-02-2024/","noteIcon":"üìù","created":"2024-03-20T00:13:20.832+07:00","updated":"2024-04-06T21:13:22.100+07:00"}
---

# Preparation

Model Merging l√† g√¨ ?

C√≥ nh·ªØng c√°ch merging n√†o ? (ƒë∆∞a ra pro, cons th√¨ c√†ng t·ªët)
- **Linear (model soups)**:
	- Uniform soup
	- Linear soup
- **Task arithemtic**
- **TIES**
	- Trim
	- Elect sign
	- Disjoint merge
- **DARE**:
- **SLERP**

Nh·ªØng d·∫°ng model quan t√¢m ƒë·ªÉ merge ?
- Hi·ªán t·∫°i ch·ªâ nh·ªØng model ƒë∆∞·ª£c fine-tuned c√πng m·ªôt base model ho·∫∑c c√°c model c√≥ c√πng architecture c≈©ng c√≥ th·ªÉ merge ƒë∆∞·ª£c. Nh·ªØng model kh√°c architecture v√≠ d·ª• nh∆∞ LLAMA, Falcon th√¨ ch∆∞a th·∫•y.
- ƒêang c√≥ trend v·ªÅ merge model stable diffusion.
# Note

- T√¨m hi·ªÉu xem c√°c tham s·ªë t·ªët c√≥ n·∫±m ·ªü layer g·∫ßn nhau kh√¥ng ?
- T√¨m hi·ªÉu xem n√™n d√πng task v·ªõi model n√†o cho experiment.
- T√¨m hi·ªÉu xem warm-up trong deep learning l√† g√¨, th·ª±c hi·ªán merge v·ªõi warm-up.